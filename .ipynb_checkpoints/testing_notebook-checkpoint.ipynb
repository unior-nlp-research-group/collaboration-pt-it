{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79691773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import ast\n",
    "\n",
    "import pprint\n",
    "\n",
    "import json\n",
    "\n",
    "import glob\n",
    "\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557872e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we use embedding only from last layer, this should stay as it is\n",
    "# it could be changed for some experiments ?\n",
    "layers = [-1]\n",
    "\n",
    "#we load the model\n",
    "#we could experiment with other models as well\n",
    "model = AutoModel.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "#these are the spacy models used to tokenize the texts and extract linguistic information\n",
    "nlp_pt = spacy.load(\"pt_core_news_sm\")\n",
    "nlp_it = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the device variable can be changed in case a GPU is available\n",
    "device = torch.device('cpu')\n",
    "#uncomment the next line to use gpu\n",
    "#device = torch.device('gpu')\n",
    "\n",
    "#the next two functions are used to extract the embeddings from tokens / sentences\n",
    "def get_hidden_states(encoded, model, layers):\n",
    "    with torch.no_grad():\n",
    "         output = model(**encoded)\n",
    "    # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_words_vector(sent, tokenizer, model, layers):\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    #token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "\n",
    "    return get_hidden_states(encoded, model, layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82955710",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.load(open(file)) for file in glob.glob('./data/*.json')]\n",
    "\n",
    "get_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbf67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to create a graph in networkx\n",
    "# + a dictionary of {token_index:embedding}\n",
    "# the graph and the dictionary are kept divided in case we would want to visualize just the graph\n",
    "\n",
    "def createGraph(tokens, sentence, relations, language):\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    edge_list = []\n",
    "    dict_embeddings = {}\n",
    "    sent_embeddings = get_words_vector(sentence, tokenizer, model, layers)\n",
    "    \n",
    "    \n",
    "    for token in tokens:\n",
    "        token_string = tokens[token]['string']\n",
    "        token_dep_id = tokens[token]['dep_id']\n",
    "        token_head = tokens[token]['dep_head_id']\n",
    "        \n",
    "        #we tokenize each word separately so we get bert subwords\n",
    "        \n",
    "        token_bert = tokenizer.tokenize(token_string, add_special_tokens=False)\n",
    "        token_idx = tokenizer.encode(token_string, add_special_tokens=False)\n",
    "        \n",
    "        token_embeddings = []\n",
    "        \n",
    "        #if a word is divided in subwords, the final embedding is the mean of the embeddings of each subword\n",
    "        for token_id in token_idx:\n",
    "            token_embeddings.append(sent_embeddings[int(token)])\n",
    "            \n",
    "        if len(token_embeddings) > 1:\n",
    "            token_embeddings = torch.stack(token_embeddings).to(device)\n",
    "            token_embeddings = torch.mean(token_embeddings, -2)\n",
    "        else:\n",
    "            try:\n",
    "                token_embeddings = token_embeddings[0]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        edge = (int(token), token_head)\n",
    "        edge_list.append(edge)\n",
    "\n",
    "        graph.add_node(int(token), label=token_string, type='token')\n",
    "        dict_embeddings[int(token)] = token_embeddings\n",
    "    \n",
    "    \n",
    "    last_added_node = list(graph.nodes())[-1]\n",
    "    #this next variable is used to extract the correct value from the dictionary\n",
    "    rel_key = f\"{language}-rel\"\n",
    "    \n",
    "    for rel in relations:\n",
    "        subj_id = last_added_node \n",
    "        obj_id = last_added_node +1\n",
    "        last_added_node +=2\n",
    "        \n",
    "        embeddings_subj = []\n",
    "        embeddings_obj = []\n",
    "        \n",
    "        graph.add_node(subj_id, label=rel[rel_key]['subj']['text'], type='entity')\n",
    "        graph.add_node(obj_id, label=rel[rel_key]['obj']['text'], type='entity')\n",
    "        \n",
    "        #for each annotated entity, the embedding is equal to the mean of the embeddings of the tokens that are present in it\n",
    "        #for instance the embedding of 'Il presidente Mario Draghi' = mean([w_il, w_presidente, w_mario, w_draghi]),\n",
    "        #with w_i being the embedding of i\n",
    "        \n",
    "        for subj_tokens in rel[rel_key]['subj']['id_tokens']:\n",
    "            graph.add_edge(int(subj_tokens), subj_id)\n",
    "            embeddings_subj.append(dict_embeddings[int(subj_tokens)])\n",
    "\n",
    "        for obj_tokens in rel[rel_key]['obj']['id_tokens']:\n",
    "            graph.add_edge(int(obj_tokens), obj_id) \n",
    "            embeddings_obj.append(dict_embeddings[int(obj_tokens)])\n",
    "        \n",
    "        #the next two exceptions are needed for some italian annotation that lacks entity\n",
    "        #unfortunately this is the only fix I could think about since the data was automatically annotated\n",
    "        try:\n",
    "            embeddings_subj = torch.stack(embeddings_subj).to(device)\n",
    "            dict_embeddings[int(subj_tokens)] = torch.mean(embeddings_subj, -2)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        try:\n",
    "            embeddings_obj = torch.stack(embeddings_obj).to(device)\n",
    "            dict_embeddings[int(obj_tokens)] = torch.mean(embeddings_obj, -2)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        graph.add_edge(edge[0], edge[1])\n",
    "        \n",
    "    \n",
    "    return graph, dict_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57de3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the next function create pairs of (source_sentence_graph, target_sentence_graph)\n",
    "\n",
    "def get_pair(data, l1, l2):\n",
    "    all_pairs = []\n",
    "    for enum, d in enumerate(data):\n",
    "        print(f\"{enum}//{len(data)}\", end='\\r')\n",
    "        for sentence in d:\n",
    "            G_source, G_emb_source = createGraph(\n",
    "                                d[sentence]['it-tokens'],\n",
    "                                d[sentence]['it-text'],\n",
    "                                d[sentence]['relations'],\n",
    "                                l1)\n",
    "            G_target, G_emb_target = createGraph(\n",
    "                                d[sentence]['pt-tokens'],\n",
    "                                d[sentence]['pt-text'],\n",
    "                                d[sentence]['relations'],\n",
    "                                l2)\n",
    "            all_pairs.append(([G_source, G_emb_source],[G_target, G_emb_target]))\n",
    "        \n",
    "    return all_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f565dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_pair(data[:3],'it', 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "696e0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example of a basic 2-layer GCN\n",
    "\n",
    "\n",
    "layer1 = GCNConv(in_channels=768, out_channels=20)\n",
    "layer2 = GCNConv(in_channels=20, out_channels=768)\n",
    "\n",
    "def tensorFromSentence(sentence):\n",
    "    G = sentence[0]\n",
    "    G_emb = sentence[1]\n",
    "    for node in G.nodes():\n",
    "        if node in G_emb:\n",
    "            G.nodes[node]['embedding'] = G_emb[node]\n",
    "        else:\n",
    "            G.nodes[node]['embedding'] = torch.rand(768)\n",
    "\n",
    "    pyg_graph = from_networkx(G)\n",
    "    out1 = layer1(torch.stack(pyg_graph['embedding']), pyg_graph.edge_index)\n",
    "    out2 = layer2(out1, pyg_graph.edge_index)\n",
    "    \n",
    "    return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72ad641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ the tested code ends here! ------#\n",
    "#------ here starts the fun part --------#\n",
    "#this decoder is a basic one from torch\n",
    "#we need to understand how this can be implemented with our embeddings\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1,1,-1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d724792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training function should go here\n",
    "#once again, this is a basic one from pytorch\n",
    "#we should customize it \n",
    "\n",
    "teacher_forcing_ration = 0.5\n",
    "\n",
    "decoder = DecoderRNN(hidden_size=20, output_size = 768)\n",
    "\n",
    "def train(input_tensor, target_tensor, decoder):\n",
    "    max_length=100\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ration else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                input_tensor, \n",
    "            )\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa20ec44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
